{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4drsTfRFlVc1"
   },
   "source": [
    "<div align=\"center\">\n",
    "  <h1>4a - Lyrics Generation - RNN</h1> <a name=\"0-bullet\"></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGlhNTaS5YQ6"
   },
   "source": [
    "- [1. Setup](#1-bullet)\n",
    "    * [1.1 Set the working directory](#11-bullet)\n",
    "    * [1.2 Load the data](#12-bullet)\n",
    "- [2. Preprocess the data](#2-bullet)\n",
    "    * [2.1 Prepare the text](#21-bullet)\n",
    "    * [2.2 Vectorize the text](#22-bullet)\n",
    "- [3. Create the training dataset](#3-bullet)\n",
    "    * [3.1 Create training examples and targets](#31-bullet)\n",
    "    * [3.2 Create training batches](#32-bullet)\n",
    "- [4. Build the model](#4-bullet)\n",
    "- [5. Model training](#5-bullet)\n",
    "    * [5.1 Configure checkpoint](#51-bullet)\n",
    "    * [5.2 Train the model](#52-bullet)\n",
    "    * [5.3 Export/load the model](#53-bullet)\n",
    "- [6. Lyrics generation](#6-bullet)\n",
    "    * [6.1 Lyrics generator model](#61-bullet)\n",
    "    * [6.2 Export/load the generator](#62-bullet)\n",
    "    * [6.3 Generate lyrics](#63-bullet)\n",
    "    * [6.4 Calculate lyrics similarity](#64-bullet)\n",
    "    * [6.5 Store lyrics to a text file](#65-bullet)\n",
    "\n",
    "> References: \n",
    "> * [TensorFlow - Text generation with an RNN](https://www.tensorflow.org/tutorials/text/text_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3l_SMrV6_5jS"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nmWOAuaSYsV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cPc1cTHl5lD"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEROGmZYl2Jc"
   },
   "source": [
    "# 1. Setup <a name=\"1-bullet\"></a> <a href=\"#0-bullet\"> <sup><sup><sup>^</sup></sup></sup></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxt8QsNGl8UQ"
   },
   "source": [
    "## 1.1 Set the working directory <a name=\"11-bullet\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20191,
     "status": "ok",
     "timestamp": 1615816012336,
     "user": {
      "displayName": "Mario Štrbac",
      "photoUrl": "",
      "userId": "03507842523962903593"
     },
     "user_tz": -60
    },
    "id": "FMVsl-WITLKy",
    "outputId": "1e418b09-7127-41bf-e7a8-964c88158103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive\n",
      "/content/gdrive/My Drive/eminem-lyrics-generator/notebooks\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = \"./eminem-lyrics-generator/notebooks/\" \n",
    "IN_GOOGLE_COLAB = True\n",
    "\n",
    "if IN_GOOGLE_COLAB:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    # change the current working directory\n",
    "    %cd gdrive/'My Drive'\n",
    "\n",
    "    # create a root directory if there's none\n",
    "    if not os.path.isdir(ROOT_DIR):\n",
    "        %mkdir $ROOT_DIR\n",
    "\n",
    "    # change the current working directory\n",
    "    %cd $ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PZiq0KNmXd1"
   },
   "source": [
    "## 1.2 Load the data <a name=\"12-bullet\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zt33pxmfFENI"
   },
   "outputs": [],
   "source": [
    "# specifies paths to all files in the project\n",
    "SETTINGS_FILE_PATH = os.path.join(os.path.abspath(\"..\"), 'SETTINGS.json')\n",
    "settings = json.load(open(SETTINGS_FILE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7sDAJETwIWeQ"
   },
   "outputs": [],
   "source": [
    "DATA_FILE_DIR = settings['LYRICS_DF_SONGS_PATH']      # 'LYRICS_DF_ALL_PATH' or 'LYRICS_DF_SONGS_PATH'\n",
    "\n",
    "with open(DATA_FILE_DIR, 'rb') as f:\n",
    "    eminem_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1615674452355,
     "user": {
      "displayName": "Mario Štrbac",
      "photoUrl": "",
      "userId": "03507842523962903593"
     },
     "user_tz": -60
    },
    "id": "taEw7CcEFVUT",
    "outputId": "73f089da-5741-44c1-de6b-29a6e8c3d6b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rap God</td>\n",
       "      <td>[Intro]\n",
       "\"Look, I was gonna go easy on you not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Killshot</td>\n",
       "      <td>[Intro]\n",
       "You sound like a bitch, bitch\n",
       "Shut the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Godzilla</td>\n",
       "      <td>[Intro]\n",
       "Ugh, you're a monster\n",
       "\n",
       "[Verse 1: Emine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lose Yourself</td>\n",
       "      <td>[Intro]\n",
       "Look, if you had one shot or one oppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Monster</td>\n",
       "      <td>[Intro: Rihanna]\n",
       "I'm friends with the monster ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Rap Game (Bump Heads)</td>\n",
       "      <td>[Intro: Eminem, DJ Butter &amp; D12 Member]\n",
       "I am n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Whoo Kid Freestyle</td>\n",
       "      <td>Step right up, i'm about to light up the skyli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Hit ’Em Up</td>\n",
       "      <td>[Intro]\n",
       "\n",
       "\"Aiyyo Head, that's why I fucked your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>The Wake Up Show Freestyle</td>\n",
       "      <td>[Verse 1]\n",
       "Met a retarded kid named Greg with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Public Service Announcement 2013</td>\n",
       "      <td>Due to a massive amount of bootlegging and con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title                                             lyrics\n",
       "0                             Rap God  [Intro]\n",
       "\"Look, I was gonna go easy on you not ...\n",
       "1                            Killshot  [Intro]\n",
       "You sound like a bitch, bitch\n",
       "Shut the...\n",
       "2                            Godzilla  [Intro]\n",
       "Ugh, you're a monster\n",
       "\n",
       "[Verse 1: Emine...\n",
       "3                       Lose Yourself  [Intro]\n",
       "Look, if you had one shot or one oppor...\n",
       "4                         The Monster  [Intro: Rihanna]\n",
       "I'm friends with the monster ...\n",
       "..                                ...                                                ...\n",
       "372             Rap Game (Bump Heads)  [Intro: Eminem, DJ Butter & D12 Member]\n",
       "I am n...\n",
       "373                Whoo Kid Freestyle  Step right up, i'm about to light up the skyli...\n",
       "374                        Hit ’Em Up  [Intro]\n",
       "\n",
       "\"Aiyyo Head, that's why I fucked your...\n",
       "375        The Wake Up Show Freestyle  [Verse 1]\n",
       "Met a retarded kid named Greg with a...\n",
       "376  Public Service Announcement 2013  Due to a massive amount of bootlegging and con...\n",
       "\n",
       "[377 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eminem_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tELT0cITnb-0"
   },
   "source": [
    "# 2. Preprocess the data <a name=\"2-bullet\"></a> <a href=\"#0-bullet\"> <sup><sup><sup>^</sup></sup></sup></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mih1oeDkEq1v"
   },
   "source": [
    "## 2.1 Prepare the text <a name=\"21-bullet\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7iz4ESDEyQa"
   },
   "source": [
    "### a) filter out songs with no section headers in the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d77LXWCDEEMu"
   },
   "outputs": [],
   "source": [
    "has_section_headers = eminem_df.lyrics.apply(lambda lyrics: \"[\" in lyrics )\n",
    "eminem_df = eminem_df[has_section_headers].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZnL-sdHGDK-"
   },
   "source": [
    "### b) add titles to the beginning of lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ooW3HTZHH2c"
   },
   "outputs": [],
   "source": [
    "eminem_lyrics_df = eminem_df.apply(lambda song: \"[Title]\\n\" + song.title + \"\\n\\n\" + song.lyrics, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiLx26dW4oIW"
   },
   "source": [
    "### c) replace triple newlines with double newlines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Gj8gqu54kvH"
   },
   "outputs": [],
   "source": [
    "eminem_lyrics_df = eminem_lyrics_df.apply(lambda lyrics: lyrics.replace('\\n\\n\\n', '\\n\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAsLTej54vcD"
   },
   "source": [
    "### d) add prefix and suffix tokens to lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHYJRHLc5rt-"
   },
   "outputs": [],
   "source": [
    "SOT = \"<SOT>\"     # start of text\n",
    "EOT = \"<EOT>\"     # end of text\n",
    "eminem_lyrics_df = eminem_lyrics_df.apply(lambda lyrics: SOT + lyrics + EOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DI8ZOhaDGJN2"
   },
   "source": [
    "### e) join all lyrics to a text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8LwkIlxEGEW"
   },
   "outputs": [],
   "source": [
    "text = '\\n\\n\\n'.join(eminem_lyrics_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzzuYsoDp9nU"
   },
   "source": [
    "## 2.2 Vectorize the text <a name=\"22-bullet\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1615744502544,
     "user": {
      "displayName": "Mario Štrbac",
      "photoUrl": "",
      "userId": "03507842523962903593"
     },
     "user_tz": -60
    },
    "id": "XiqiX4JZsBhC",
    "outputId": "cfb00107-de9e-49bb-a992-ebbd2dc7bdf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1411222 characters\n",
      "116 unique characters\n"
     ]
    }
   ],
   "source": [
    "# length of the text in chars\n",
    "print('Length of text: {} characters'.format(len(text)))\n",
    "\n",
    "# unique chars in the text\n",
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VhHR0FRW17e"
   },
   "outputs": [],
   "source": [
    "# converting characters into ids and ids into characters\n",
    "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab))\n",
    "chars_from_ids = preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), \n",
    "                                            invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2M3Z1MOaNAp"
   },
   "outputs": [],
   "source": [
    "# helper function to get text from ids\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrrfdbIaqOBM"
   },
   "source": [
    "# 3. Create the training dataset <a name=\"3-bullet\"></a> <a href=\"#0-bullet\"> <sup><sup><sup>^</sup></sup></sup></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhrmGxBpAYnv"
   },
   "source": [
    "## 3.1 Create training examples and targets <a name=\"31-bullet\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5CMvac7aVTj"
   },
   "outputs": [],
   "source": [
    "# split the text into chars and encode it to ids\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "# create a dataset from the ids\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "# divide the dataset into sequences/examples\n",
    "SEQ_LENGTH = 3000 \n",
    "sequences = ids_dataset.batch(SEQ_LENGTH + 1, drop_remainder=True)\n",
    "\n",
    "# create the train dataset by splitting each sequence into input text and target text \n",
    "dataset = sequences.map(lambda sequence: (sequence[:-1], sequence[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xxqXI_lAvT-"
   },
   "source": [
    "## 3.2 Create training batches <a name=\"32-bullet\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0EDAelUb6Ll"
   },
   "outputs": [],
   "source": [
    "# buffer size to shuffle the dataset\n",
    "BUFFER_SIZE = 10000\n",
    "# batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE) \\\n",
    "                 .batch(BATCH_SIZE, drop_remainder=True) \\\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYxRP7NVf8RN"
   },
   "source": [
    "# 4. Build the model <a name=\"4-bullet\"></a> <a href=\"#0-bullet\"> <sup><sup><sup>^</sup></sup></sup></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdNS-crxlBU4"
   },
   "source": [
    "### a) construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdV2Rld9AUEm"
   },
   "outputs": [],
   "source": [
    "# embedding dimension\n",
    "EMBEDDING_DIM = 256\n",
    "# number of RNN units\n",
    "RNN_UNITS = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yC8N8STTcJXK"
   },
   "outputs": [],
   "source": [
    "# length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        # input/embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        # rnn layer\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                      return_sequences=True, \n",
    "                                      return_state=True)\n",
    "        # output layer\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        # input/embedding layer output\n",
    "        x = self.embedding(inputs, training=training)\n",
    "\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        # rnn layer output\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        \n",
    "        # output/dense layer output\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vaj3AtLjlL9y"
   },
   "source": [
    "### b) init the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPzVckl7dufh"
   },
   "outputs": [],
   "source": [
    "model = MyModel(vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "                embedding_dim=EMBEDDING_DIM,\n",
    "                rnn_units=RNN_UNITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZJ5QbbMYWe6"
   },
   "source": [
    "# 5. Model Training <a name=\"5-bullet\"></a> <a href=\"#0-bullet\"> <sup><sup><sup>^</sup></sup></sup></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qm8eK2cBZ6yz"
   },
   "source": [
    "## 5.1 Configure checkpoint <a name=\"51-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ulreh6abYhC"
   },
   "outputs": [],
   "source": [
    "RNN_MODEL_DIR = settings['RNN_MODEL_DIR']\n",
    "CHECKPOINT_DIR = os.path.join(RNN_MODEL_DIR, 'training_checkpoints')\n",
    "CHECKPOINT_PREFIX = os.path.join(CHECKPOINT_DIR, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINT_PREFIX,\n",
    "                                                         save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHJ2rwlSbl7N"
   },
   "source": [
    "## 5.2 Train the model <a name=\"52-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9070899,
     "status": "ok",
     "timestamp": 1615753644813,
     "user": {
      "displayName": "Mario Štrbac",
      "photoUrl": "",
      "userId": "03507842523962903593"
     },
     "user_tz": -60
    },
    "id": "MaVb029zjY1Y",
    "outputId": "94be8b85-6197-4374-fec7-3b73487a2a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "7/7 [==============================] - 30s 4s/step - loss: 5.0460\n",
      "Epoch 2/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 4.0735\n",
      "Epoch 3/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 3.5481\n",
      "Epoch 4/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 3.2036\n",
      "Epoch 5/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 3.1013\n",
      "Epoch 6/350\n",
      "7/7 [==============================] - 28s 4s/step - loss: 3.0032\n",
      "Epoch 7/350\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.8832\n",
      "Epoch 8/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.7734\n",
      "Epoch 9/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.6840\n",
      "Epoch 10/350\n",
      "7/7 [==============================] - 28s 4s/step - loss: 2.6139\n",
      "Epoch 11/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.5477\n",
      "Epoch 12/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.5009\n",
      "Epoch 13/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.4594\n",
      "Epoch 14/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.4283\n",
      "Epoch 15/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.4053\n",
      "Epoch 16/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.3766\n",
      "Epoch 17/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.3502\n",
      "Epoch 18/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.3270\n",
      "Epoch 19/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.3046\n",
      "Epoch 20/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.2859\n",
      "Epoch 21/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.2582\n",
      "Epoch 22/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.2402\n",
      "Epoch 23/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.2142\n",
      "Epoch 24/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.1852\n",
      "Epoch 25/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.1621\n",
      "Epoch 26/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.1348\n",
      "Epoch 27/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.1104\n",
      "Epoch 28/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.0814\n",
      "Epoch 29/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.0532\n",
      "Epoch 30/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 2.0284\n",
      "Epoch 31/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 2.0043\n",
      "Epoch 32/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.9819\n",
      "Epoch 33/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.9562\n",
      "Epoch 34/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.9376\n",
      "Epoch 35/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.9126\n",
      "Epoch 36/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.8964\n",
      "Epoch 37/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.8712\n",
      "Epoch 38/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.8561\n",
      "Epoch 39/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.8407\n",
      "Epoch 40/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.8180\n",
      "Epoch 41/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.8031\n",
      "Epoch 42/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.7858\n",
      "Epoch 43/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.7658\n",
      "Epoch 44/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.7539\n",
      "Epoch 45/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.7340\n",
      "Epoch 46/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.7201\n",
      "Epoch 47/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.7056\n",
      "Epoch 48/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.6959\n",
      "Epoch 49/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.6765\n",
      "Epoch 50/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.6625\n",
      "Epoch 51/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.6495\n",
      "Epoch 52/350\n",
      "7/7 [==============================] - 28s 4s/step - loss: 1.6375\n",
      "Epoch 53/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.6247\n",
      "Epoch 54/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.6168\n",
      "Epoch 55/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.5997\n",
      "Epoch 56/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.5876\n",
      "Epoch 57/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.5750\n",
      "Epoch 58/350\n",
      "7/7 [==============================] - 28s 4s/step - loss: 1.5623\n",
      "Epoch 59/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.5560\n",
      "Epoch 60/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.5469\n",
      "Epoch 61/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.5270\n",
      "Epoch 62/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.5235\n",
      "Epoch 63/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.5119\n",
      "Epoch 64/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.4997\n",
      "Epoch 65/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.4888\n",
      "Epoch 66/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.4784\n",
      "Epoch 67/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.4674\n",
      "Epoch 68/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.4671\n",
      "Epoch 69/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.4578\n",
      "Epoch 70/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.4493\n",
      "Epoch 71/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.4329\n",
      "Epoch 72/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.4321\n",
      "Epoch 73/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.4246\n",
      "Epoch 74/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.4078\n",
      "Epoch 75/350\n",
      "7/7 [==============================] - 28s 4s/step - loss: 1.4048\n",
      "Epoch 76/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.4009\n",
      "Epoch 77/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3904\n",
      "Epoch 78/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3798\n",
      "Epoch 79/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3726\n",
      "Epoch 80/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.3661\n",
      "Epoch 81/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.3530\n",
      "Epoch 82/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3487\n",
      "Epoch 83/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3385\n",
      "Epoch 84/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3359\n",
      "Epoch 85/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3250\n",
      "Epoch 86/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3173\n",
      "Epoch 87/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3162\n",
      "Epoch 88/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3091\n",
      "Epoch 89/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.3084\n",
      "Epoch 90/350\n",
      "7/7 [==============================] - 28s 4s/step - loss: 1.2953\n",
      "Epoch 91/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.2891\n",
      "Epoch 92/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.2839\n",
      "Epoch 93/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.2738\n",
      "Epoch 94/350\n",
      "7/7 [==============================] - 28s 4s/step - loss: 1.2744\n",
      "Epoch 95/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.2644\n",
      "Epoch 96/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.2551\n",
      "Epoch 97/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.2558\n",
      "Epoch 98/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.2435\n",
      "Epoch 99/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.2355\n",
      "Epoch 100/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.2258\n",
      "Epoch 101/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.2301\n",
      "Epoch 102/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.2165\n",
      "Epoch 103/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.2142\n",
      "Epoch 104/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.2076\n",
      "Epoch 105/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.1990\n",
      "Epoch 106/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1913\n",
      "Epoch 107/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.1863\n",
      "Epoch 108/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.1755\n",
      "Epoch 109/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1669\n",
      "Epoch 110/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.1685\n",
      "Epoch 111/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.1659\n",
      "Epoch 112/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.1579\n",
      "Epoch 113/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.1493\n",
      "Epoch 114/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1426\n",
      "Epoch 115/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.1408\n",
      "Epoch 116/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.1389\n",
      "Epoch 117/350\n",
      "7/7 [==============================] - 28s 4s/step - loss: 1.1257\n",
      "Epoch 118/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1141\n",
      "Epoch 119/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.1128\n",
      "Epoch 120/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.1066\n",
      "Epoch 121/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 1.0984\n",
      "Epoch 122/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 1.0890\n",
      "Epoch 123/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.0849\n",
      "Epoch 124/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.0844\n",
      "Epoch 125/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.0787\n",
      "Epoch 126/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.0712\n",
      "Epoch 127/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.0655\n",
      "Epoch 128/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.0608\n",
      "Epoch 129/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.0495\n",
      "Epoch 130/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.0452\n",
      "Epoch 131/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 1.0366\n",
      "Epoch 132/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.0360\n",
      "Epoch 133/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.0238\n",
      "Epoch 134/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.0086\n",
      "Epoch 135/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 1.0112\n",
      "Epoch 136/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.0085\n",
      "Epoch 137/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 1.0015\n",
      "Epoch 138/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.9970\n",
      "Epoch 139/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9997\n",
      "Epoch 140/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9850\n",
      "Epoch 141/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9818\n",
      "Epoch 142/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9691\n",
      "Epoch 143/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9655\n",
      "Epoch 144/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9530\n",
      "Epoch 145/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9480\n",
      "Epoch 146/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9434\n",
      "Epoch 147/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9372\n",
      "Epoch 148/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9413\n",
      "Epoch 149/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9237\n",
      "Epoch 150/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9174\n",
      "Epoch 151/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9117\n",
      "Epoch 152/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9045\n",
      "Epoch 153/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.8962\n",
      "Epoch 154/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.9020\n",
      "Epoch 155/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.9013\n",
      "Epoch 156/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.8811\n",
      "Epoch 157/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.8733\n",
      "Epoch 158/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.8663\n",
      "Epoch 159/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.8737\n",
      "Epoch 160/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.8542\n",
      "Epoch 161/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.8490\n",
      "Epoch 162/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.8359\n",
      "Epoch 163/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.8306\n",
      "Epoch 164/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.8311\n",
      "Epoch 165/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.8239\n",
      "Epoch 166/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.8129\n",
      "Epoch 167/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.8145\n",
      "Epoch 168/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.8068\n",
      "Epoch 169/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7976\n",
      "Epoch 170/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7900\n",
      "Epoch 171/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7811\n",
      "Epoch 172/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7765\n",
      "Epoch 173/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7748\n",
      "Epoch 174/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7648\n",
      "Epoch 175/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.7583\n",
      "Epoch 176/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7633\n",
      "Epoch 177/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7485\n",
      "Epoch 178/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7318\n",
      "Epoch 179/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7422\n",
      "Epoch 180/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7375\n",
      "Epoch 181/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7201\n",
      "Epoch 182/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7195\n",
      "Epoch 183/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7068\n",
      "Epoch 184/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6984\n",
      "Epoch 185/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6924\n",
      "Epoch 186/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6968\n",
      "Epoch 187/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6866\n",
      "Epoch 188/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.7018\n",
      "Epoch 189/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6744\n",
      "Epoch 190/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6656\n",
      "Epoch 191/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6513\n",
      "Epoch 192/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6715\n",
      "Epoch 193/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6576\n",
      "Epoch 194/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6373\n",
      "Epoch 195/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6253\n",
      "Epoch 196/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6354\n",
      "Epoch 197/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6391\n",
      "Epoch 198/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6130\n",
      "Epoch 199/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5990\n",
      "Epoch 200/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6144\n",
      "Epoch 201/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.6157\n",
      "Epoch 202/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6059\n",
      "Epoch 203/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5914\n",
      "Epoch 204/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5825\n",
      "Epoch 205/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5719\n",
      "Epoch 206/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5785\n",
      "Epoch 207/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5729\n",
      "Epoch 208/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5529\n",
      "Epoch 209/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5466\n",
      "Epoch 210/350\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.5729\n",
      "Epoch 211/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5522\n",
      "Epoch 212/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5482\n",
      "Epoch 213/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5330\n",
      "Epoch 214/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5406\n",
      "Epoch 215/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5138\n",
      "Epoch 216/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5165\n",
      "Epoch 217/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5217\n",
      "Epoch 218/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.5151\n",
      "Epoch 219/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.5109\n",
      "Epoch 220/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.5051\n",
      "Epoch 221/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.4970\n",
      "Epoch 222/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.4932\n",
      "Epoch 223/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.4782\n",
      "Epoch 224/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4773\n",
      "Epoch 225/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.5135\n",
      "Epoch 226/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.4738\n",
      "Epoch 227/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4581\n",
      "Epoch 228/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4598\n",
      "Epoch 229/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4854\n",
      "Epoch 230/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.4518\n",
      "Epoch 231/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.4473\n",
      "Epoch 232/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4279\n",
      "Epoch 233/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4499\n",
      "Epoch 234/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.4395\n",
      "Epoch 235/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.4320\n",
      "Epoch 236/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.4177\n",
      "Epoch 237/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.4308\n",
      "Epoch 238/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.4166\n",
      "Epoch 239/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4033\n",
      "Epoch 240/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4010\n",
      "Epoch 241/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.3951\n",
      "Epoch 242/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.4065\n",
      "Epoch 243/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4023\n",
      "Epoch 244/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.3999\n",
      "Epoch 245/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3930\n",
      "Epoch 246/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3839\n",
      "Epoch 247/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.4084\n",
      "Epoch 248/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3812\n",
      "Epoch 249/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3594\n",
      "Epoch 250/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3613\n",
      "Epoch 251/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.3786\n",
      "Epoch 252/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3610\n",
      "Epoch 253/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.3489\n",
      "Epoch 254/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.3451\n",
      "Epoch 255/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3867\n",
      "Epoch 256/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.3631\n",
      "Epoch 257/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3461\n",
      "Epoch 258/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3363\n",
      "Epoch 259/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3316\n",
      "Epoch 260/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3333\n",
      "Epoch 261/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.3438\n",
      "Epoch 262/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3279\n",
      "Epoch 263/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.3198\n",
      "Epoch 264/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3129\n",
      "Epoch 265/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3100\n",
      "Epoch 266/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3100\n",
      "Epoch 267/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.3174\n",
      "Epoch 268/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3021\n",
      "Epoch 269/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3000\n",
      "Epoch 270/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.2976\n",
      "Epoch 271/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.3107\n",
      "Epoch 272/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3080\n",
      "Epoch 273/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2976\n",
      "Epoch 274/350\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.2901\n",
      "Epoch 275/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2860\n",
      "Epoch 276/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.3013\n",
      "Epoch 277/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2772\n",
      "Epoch 278/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2744\n",
      "Epoch 279/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2593\n",
      "Epoch 280/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2641\n",
      "Epoch 281/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2813\n",
      "Epoch 282/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2848\n",
      "Epoch 283/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2725\n",
      "Epoch 284/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2706\n",
      "Epoch 285/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.2592\n",
      "Epoch 286/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2474\n",
      "Epoch 287/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2403\n",
      "Epoch 288/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2355\n",
      "Epoch 289/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2320\n",
      "Epoch 290/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2914\n",
      "Epoch 291/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.3558\n",
      "Epoch 292/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2958\n",
      "Epoch 293/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.2738\n",
      "Epoch 294/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2622\n",
      "Epoch 295/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2417\n",
      "Epoch 296/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2286\n",
      "Epoch 297/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2196\n",
      "Epoch 298/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2086\n",
      "Epoch 299/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.2041\n",
      "Epoch 300/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2009\n",
      "Epoch 301/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2007\n",
      "Epoch 302/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2131\n",
      "Epoch 303/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.3016\n",
      "Epoch 304/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2651\n",
      "Epoch 305/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2439\n",
      "Epoch 306/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.2214\n",
      "Epoch 307/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2087\n",
      "Epoch 308/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.2016\n",
      "Epoch 309/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1897\n",
      "Epoch 310/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1843\n",
      "Epoch 311/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1790\n",
      "Epoch 312/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1747\n",
      "Epoch 313/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.1726\n",
      "Epoch 314/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.1902\n",
      "Epoch 315/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2884\n",
      "Epoch 316/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2586\n",
      "Epoch 317/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2397\n",
      "Epoch 318/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.2250\n",
      "Epoch 319/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.2111\n",
      "Epoch 320/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.1950\n",
      "Epoch 321/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1814\n",
      "Epoch 322/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1720\n",
      "Epoch 323/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1648\n",
      "Epoch 324/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1572\n",
      "Epoch 325/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1519\n",
      "Epoch 326/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1491\n",
      "Epoch 327/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.1433\n",
      "Epoch 328/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1447\n",
      "Epoch 329/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1406\n",
      "Epoch 330/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.1456\n",
      "Epoch 331/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.1438\n",
      "Epoch 332/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1492\n",
      "Epoch 333/350\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.1482\n",
      "Epoch 334/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1533\n",
      "Epoch 335/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.1661\n",
      "Epoch 336/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2669\n",
      "Epoch 337/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.2576\n",
      "Epoch 338/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.2418\n",
      "Epoch 339/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.2101\n",
      "Epoch 340/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.1925\n",
      "Epoch 341/350\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.1735\n",
      "Epoch 342/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1629\n",
      "Epoch 343/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.1463\n",
      "Epoch 344/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.1384\n",
      "Epoch 345/350\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1309\n",
      "Epoch 346/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.1265\n",
      "Epoch 347/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.1206\n",
      "Epoch 348/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.1170\n",
      "Epoch 349/350\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.1128\n",
      "Epoch 350/350\n",
      "7/7 [==============================] - 25s 3s/step - loss: 0.1102\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 250\n",
    "\n",
    "# configure the training procedure\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTgIFxUe8Ux4"
   },
   "source": [
    "## 5.3 Export/load the model <a name=\"53-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xmo_a9FXZwp"
   },
   "source": [
    "### a) Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2800,
     "status": "ok",
     "timestamp": 1615753668508,
     "user": {
      "displayName": "Mario Štrbac",
      "photoUrl": "",
      "userId": "03507842523962903593"
     },
     "user_tz": -60
    },
    "id": "Drb-HzUdXeL7",
    "outputId": "769566a8-342e-4cb1-ea26-4d406cfea79d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/rnn_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(settings['RNN_MODEL_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDr-ni6uXcrh"
   },
   "source": [
    "### b) Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01Bh6p5w8dBe"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(settings['RNN_MODEL_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQrk5gFwb6EQ"
   },
   "source": [
    "# 6. Lyrics generation <a name=\"6-bullet\"></a> <a href=\"#0-bullet\"> <sup><sup><sup>^</sup></sup></sup></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgCWpRDwZ3RD"
   },
   "source": [
    "## 6.1 Lyrics generator model <a name=\"61-bullet\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMFCB6R_dCbR"
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature=temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # create a mask to prevent \"\" or \"[UNK]\" from being generated\n",
    "        skip_ids = self.ids_from_chars(['','[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(values=[-float('inf')]*len(skip_ids),     # put a -inf at each bad index\n",
    "                                      indices=skip_ids,                         \n",
    "                                      dense_shape=[len(ids_from_chars.get_vocabulary())])   # match the shape to the vocabulary\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # convert strings to token IDs\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # run the model\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits] \n",
    "        predicted_logits, states =  self.model(inputs=input_ids, \n",
    "                                               states=states, \n",
    "                                               return_state=True)\n",
    "        # only use the last prediction\n",
    "        predicted_logits = predicted_logits[:,-1, :]\n",
    "        predicted_logits = predicted_logits / self.temperature\n",
    "        # apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # sample the output logits to generate token IDs\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # return the characters and model state\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQ9Ubm0y6EXG"
   },
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars, temperature=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEEU9GCiZ5ZR"
   },
   "source": [
    "## 6.2 Export/load the generator <a name=\"62-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sE-Nu6NZZ8_w"
   },
   "source": [
    "### a) Export the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2594,
     "status": "ok",
     "timestamp": 1615753681892,
     "user": {
      "displayName": "Mario Štrbac",
      "photoUrl": "",
      "userId": "03507842523962903593"
     },
     "user_tz": -60
    },
    "id": "L5kxFTSGZ9sU",
    "outputId": "367bd598-b381-47f9-8373-c2ec4334ceb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7fb8727325d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.preprocessing.string_lookup.StringLookup object at 0x7fb8cf59e110>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as generate_one_step while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as generate_one_step while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/one_step_generator/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/one_step_generator/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, settings['RNN_GENERATOR_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LieE8bkeZ-D_"
   },
   "source": [
    "### b) Load the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vMhq4-fZ_Ht"
   },
   "outputs": [],
   "source": [
    "one_step_reloaded = tf.saved_model.load(settings['RNN_GENERATOR_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuSywj3ZZ_6_"
   },
   "source": [
    "## 6.3 Generate lyrics <a name=\"63-bullet\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7970,
     "status": "ok",
     "timestamp": 1615754150183,
     "user": {
      "displayName": "Mario Štrbac",
      "photoUrl": "",
      "userId": "03507842523962903593"
     },
     "user_tz": -60
    },
    "id": "TNxJ8zEueT56",
    "outputId": "6b050655-7f22-4464-cafa-3aba0e122669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Title]\n",
      "Artificial Intelligence\n",
      "\n",
      "[Intro]\n",
      "Uh, uh, uh, uh, alain, debridee\n",
      "You know I just be sayin' that to get you mad\n",
      "And when I rap about a buncha shit you wished you had\n",
      "(A wish) Uh (Ban!)\n",
      "We're bullets, you did it! I'm so sing and get to do again\n",
      "\n",
      "[Verse 2: Eminem]\n",
      "Yeah, you're gonna get in it\n",
      "But I still wanna fight yeur of a Slim Shady irony\n",
      "If we are Slamm in a Jordnes are going his own diant\n",
      "Who's got these huggs that don't make is thinkin'\n",
      "You motherfuckers 'cause he ain't shows with no remorse for you\n",
      "We start on 'cause I am not a lastrone who want a Goddimate, Axact\n",
      "Or blowin' up like ferty murdered the shells and leave you swallowed a little line\n",
      "Ain't no one nappin' it off the feal in half\n",
      "Caught in a chair, man, how come here?\n",
      "Fay-back dum\n",
      "All by once the fuck you think I want from me?\n",
      "I'm a freak, I'm just thinky's simple as dellain and boys like\n",
      "You hope the matter-window with you\n",
      "Blockbate, keep ya head up a little like Conociance\n",
      "Little faggots teacher did this well-bieed\n",
      "Maybe Shat's guts in my house and flato slow\n",
      "Hope you cannot trade tasic this mouth\n",
      "Then they keep on provocy times and every time that she cates\n",
      "The green is formin', gettin' fired, but her neck\n",
      "Isl' best will I ever saw him dyularolm\n",
      "Oh, Dog what? I told you this kid's only thing\n",
      "I'm there for that, no quick take another private charts\n",
      "And I'm punchin' the same pounds\n",
      "And hold of my clothes out, then we can stable hears\n",
      "'Cause it feels so ride or die to ya black skinny probably\n",
      "'Cause the last time I tried to flown a though screaming\n",
      "I'm 'bout to look at it, hangin' on that shit\n",
      "I'm at your throat, I'm desperation go\n",
      "'Cause that's just the way things can keep sicked it\n",
      "I ain't sayin' this and put in my rack\n",
      "Grab somebody fun in the woods, where the body was double Delardoes (Feer girls) I stepped on your villas, makin' mode (Oh shit at the end of the million shit)\n",
      "You think there's a genther, in this world (This tone), to rock at it, so do I am (Shit is me)\n",
      "Now here I come, I bet your all about my liters (Uh-that's whos)\n",
      "Where I had a wide of the Vennismin (Yeah)\n",
      "Stupid for every time the sign callin' at your true\n",
      "Now atticule to \"hop my turns and driven when they call me \"Ahad!\n",
      "Somebody here now in coss crack and said, \"Yeah bumb?)\n",
      "I'm right in your man and horraggers, cut the fucking chick with a canison and began\n",
      "The shit's about to teas 'round the club\n",
      "'Til I helpa in eighteen in in, pundin' the rack\n",
      "And I ain't talkin' shit and lock his skull (Now)\n",
      "Sorry, please, Mom, please come back to you\n",
      "So everybody even if it seems to beat the shelver grous!\n",
      "\n",
      "[Chorus]\n",
      "I'm not happy here (Nah), with her\n",
      "Rather have you (Yeah), rather have me too\n",
      "'Cause you're not happy there (You're not happy there), with him\n",
      "Rather have me (I know, but), we’re just in too deep\n",
      "\n",
      "[Verse 2]\n",
      "What go on us, Scraw my ass head spray Face has a paradox\n",
      "\n",
      "[Verse 2: Eminem]\n",
      "I'm not a pissed on you—\n",
      "\n",
      "[Pre-Chorus: Eminem]\n",
      "Kick yo' is still doubters\n",
      "Slap a bitch and smack a hoes\n",
      "'Cause I'm for broke as fuck\n",
      "Someone got hit with a headache, give me the jaws\n",
      "Keep know that you should remember\n",
      "Sometimes things start to get it conts, unifationally buliniss more\n",
      "But you ain't nothin' to work a shred, I'm cumped\n",
      "'Cause you're dissin' again\n",
      "I'll be a pissin' off all they say\n",
      "\"I need a new outle you, no\n",
      "You're a goner, beyond she'd like your neck\n",
      "You battle this, so you better be refears (Nurs, Just Blaze on ma)\n",
      "Hang up to me I'm like a verbal fucked up like BrickER\n",
      "Style of Rudy, killed king off the bitch, oh, shit!\n",
      "Pellor barkelf another lie to eye couper, senk the demon\n",
      "Charted Poll, with his headphones behind a job for the Sewner with RunychMar\n",
      "Shrodgen my knife so the champ\n",
      "You get back together full coddin beast\n",
      "So what? Give me an end out with\n",
      "Baby goodbye to Hollywood\n",
      "Sayin' goodbye, sayin' goodbye to Hollywood, who do shit\n",
      "'Cause he can ball it eaght and put up a fight\n",
      "When you scream \"I'd be cray-roas!\"\n",
      "I'm not the only one who'll beat a lick that\n",
      "Well, fuck the fucking dogs or somethin' to pull\n",
      "And his soul so in another for her\n",
      "Fuck that! At chut?\n",
      "You'll never dagg then I lare was and kill it\n",
      "I spit it slow, sed with someone to be the subar shifters, pennies 'em\n",
      "'Cause my breathin' and spreading with diamonds off the line\n",
      "Splash open, echions in Jesus\n",
      "I need for no gunpowness\n",
      "Cut your mom with my crew halful when you stuck a switch\n",
      "Lookin' so faster, so the show's gettin' checked room\n",
      "And it's going on not, it's like things in a ratchy coach and I'm pullin' the pass\n",
      "That's why I tucked to the five launch if it's your five\n",
      "So my nigga guys, yeah, still while I'm on 'em\n",
      "My living rough to avoct one don' how to came to Christina\n",
      "And the fans and the way to think that they was just the other mind\n",
      "I don't give a fuck, and lick a dollar sounds\n",
      "But I'ma still got the neighborhood of the track\n",
      "\n",
      "[\n"
     ]
    }
   ],
   "source": [
    "# start and end of text tokens\n",
    "SOT = \"<SOT>\"\n",
    "EOT = \"<EOT>\"\n",
    "\n",
    "# lyrics length in chars\n",
    "LYRICS_LENGTH = 4800\n",
    "\n",
    "SONG_TITLE = 'Artificial Intelligence'\n",
    "\n",
    "next_char = tf.constant([SOT + '[Title]\\n' + SONG_TITLE + '\\n\\n'])\n",
    "result = [next_char]\n",
    "states = None\n",
    "\n",
    "# for tracking the last five generated chars - to detect the end of text token\n",
    "last_5_chars = \"\"\n",
    "\n",
    "for n in range(LYRICS_LENGTH):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "    # track the last five chars \n",
    "    last_5_chars = (last_5_chars + next_char.numpy()[0].decode(\"utf-8\"))[-5:]\n",
    "    # stop the generation if EOT is detected\n",
    "    if last_5_chars==EOT:\n",
    "        break\n",
    "\n",
    "# convert to string\n",
    "result = tf.strings.join(result)[0].numpy().decode('utf-8')\n",
    "# remove the SOT token\n",
    "result = result[5:]\n",
    "# remove the EOT token if the generation ended with one\n",
    "gen_lyrics = result[:-5] if last_5_chars==EOT else result\n",
    "\n",
    "print(gen_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS2pkY7ZOhjd"
   },
   "source": [
    "## 6.4 Calculate lyrics similarity <a name=\"64-bullet\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1615755004067,
     "user": {
      "displayName": "Mario Štrbac",
      "photoUrl": "",
      "userId": "03507842523962903593"
     },
     "user_tz": -60
    },
    "id": "1sl9gr0JOhVT",
    "outputId": "9cd0d639-762c-48be-ba54-e19a17879b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Artificial Intelligence\n",
      "Similar: The Re-Up, 2004 Tim Westwood Freestyle, Eminem Freestyles on Tim Westwood | 2010\n",
      "Scores: 0.345, 0.153, 0.152\n",
      "Corpus: [255 309 198]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# put the generated text to the top of the lyrics corpus\n",
    "lyrics = np.concatenate([[gen_lyrics], eminem_lyrics_df.values])\n",
    "# transform lyrics into TF-IDF vectors\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\").fit_transform(lyrics)\n",
    "\n",
    "# compute the cosine similarity  \n",
    "pairwise_similarity = tfidf * tfidf.T \n",
    "# isolate only the top row (the row with similarities for the generated text)\n",
    "pairwise_similarity = pairwise_similarity.toarray()[0]\n",
    "# mask the diagonal element (the similarity to itself)\n",
    "pairwise_similarity[0] = -1\n",
    "\n",
    "# get the top 3 most similar lyrics to the generated text\n",
    "most_similar_idxs = pairwise_similarity.argsort()[-3:][::-1] \n",
    "\n",
    "# list of things to print\n",
    "output = [SONG_TITLE,\n",
    "          ', '.join(eminem_df.iloc[most_similar_idxs - 1].title), \n",
    "          *pairwise_similarity[most_similar_idxs], \n",
    "          most_similar_idxs - 1]\n",
    "\n",
    "print(\"Title: {}\\nSimilar: {:50s}\\nScores: {:.3f}, {:.3f}, {:.3f}\\nCorpus: {}\\n\".format(*output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Hq3unoqUAv6"
   },
   "source": [
    "## 6.5 Store lyrics to a text file <a name=\"65-bullet\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6odmlCkfUBFk"
   },
   "outputs": [],
   "source": [
    "GENERATED_LYRICS_DIR = settings['GENERATED_LYRICS_DIR']\n",
    "FILE_NAME = \"rnn_model_lyrics.txt\"\n",
    "DELIMITER = '\\n\\n\\n'\n",
    "\n",
    "with open(os.path.join(GENERATED_LYRICS_DIR, FILE_NAME), \"a\") as text_file:\n",
    "    text_file.write(gen_lyrics + DELIMITER)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4-a-Lyrics-Generation-RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
